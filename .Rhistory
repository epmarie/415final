norm_errors <- function(errors){
# normalizes the errors based on the mean
errors$total <- rowSums(errors[,!(colnames(errors) %in% c("id", "model", "reference_flag"))], na.rm = TRUE)
cols <- colnames(errors)[!(colnames(errors) %in% c("id", "model", "reference_flag"))]
for (col in cols){
errors[, col] <- errors[, col]/median(errors[, col])
}
return(errors)
}
scores <- function(predictions, N=10){
# function to quanitfy the ability to correctly classifying models as native or non-native
# returns the NSLR and the fraction of the high probability models that are considered native
require(nmR)
return(data.frame(NSLR=nslr(predictions$reference_flag), TOPN=mean(as.numeric(predictions$reference_flag[1:N])-1)))
}
nslr <- function(X){
#' Sum of Logarithmic Ranks Function
#'
#' This function allows you to compute the normalized sum of logarithmic ranks
#' @param X vector of 0 (inactives) and 1 (actives) that was sorted based on some scores (e.g., agreement between measured and predicted shifts)
#' @export
#' @examples
#' random_nslr(sample(c(rep(0,100),rep(1,10))))
isfar
ri <- which(X==1)
N <- length(X)
i <-  1:length(ri)
SLRmax <- -sum(log(i/N)) # logo rank
return(-sum(log(ri/N))/SLRmax)
}
# load errors matrices
load("\Users\Brett\Downloads\errors_consensus_r0.RData")
# scramble data just to be sure
errors <- errors[sample(1:nrow(errors)),]
# normalize the error for each RNA (specificed by id) separately
library(plyr)
library(dplyr)
errors <- ddply(.data = errors, .variables = c("id"), .fun = norm_errors)
errors <- as.data.frame(errors)
# make sure the reference_flag is a factor so that when used in randomForest will recognize this as a classification problem
errors$reference_flag <- as.factor(errors$reference_flag)
# SPLIT INTO TRAINING AND TESTING
# choosing training and testing RNAs
train_rnas = "1KKA 1L1W 1LC6 1LDZ 1NC0 1OW9 1PJY 1R7W 1SCL 1UUU 1XHP 1YSV 1Z2J 1ZC5 2FDT 2JWV 2K66 2KOC 2L3E 2LBJ 2LBL 2LDL 2LDT 2LHP 2LI4 2LK3 2LP9 2LPA 2LQZ 2LU0 2LUB"
test_rnas = "2LUN 2LV0 2M12 2M21 2M22 2M24 2M4W 2M5U 2M8K 2MEQ 2MFD 2MHI 2MNC 2MXL 2N2O 2N2P 2N4L 2N6S 2N6T 2N6W 2N6X"
train_rnas <- unlist(strsplit(train_rnas, " "))
test_rnas <- unlist(strsplit(test_rnas, " "))
train <- errors[(errors$id %in% train_rnas), !(colnames(errors) %in% c("id", "model"))]
test <- errors[(errors$id %in% test_rnas), !(colnames(errors) %in% c("id", "model"))]
test_info <- errors[(errors$id %in% test_rnas), (colnames(errors) %in% c("id", "model"))]
train[is.na(train)] <- 9999
test[is.na(test)] <- 9999
# set column names for training and testing dataframes
names <- unlist(strsplit("reference_flag C1p C2p C3p C4p C5p C2 C5 C6 C8 H1p H2p H3p H4p H5p H5pp H2 H5 H6 H8 total", " "))
colnames(train) <- names
colnames(test) <- names
# Logic to balance training set
n_true <- sum(train$reference_flag==1)
n_false <- sum(train$reference_flag==0)
n_minor <- abs(n_true-n_false)
train_true <- subset(train, reference_flag==1)
train_false <- subset(train, reference_flag==0)
train_balance <-  rbind(train_true, rbind(train_false, train_false[sample(1:nrow(train_false), n_minor, replace = TRUE), ]))
# BUILD CLASSIFIER
library(randomForest)
library(caret)
rf <- randomForest(formula = reference_flag~., data = train_balance, na.action = na.exclude, do.trace = TRUE, ntree = 500, cutoff = c(0.6,0.4))
# Make predictions using classifier
test$reference_flag_binary <- predict(rf, test, type = "response")
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
test <- cbind(test_info, test)
# get performance after sorting based on total error
test <- test[order(test[,c("total")], decreasing = FALSE), ]
test_nslr_total_error <- ddply(.data = test, .variables = c("id"), .fun = scores, N=1)
# get nmR package ready to use
install.packages("nmR")
library("nmR")
# get performance after sorting based on predicted probability of being native
test <- test[order(test[,c("reference_flag_prob")][,1]), ]
test_nslr_class <- ddply(.data = test, .variables = c("id"), .fun = scores, N=1)
# compare results obtained when using the total error and classifier
print(cbind(test_nslr_total_error, test_nslr_class))
load("\Users\Brett\Downloads\errors_consensus_r0.RData")
errors <- errors[sample(1:nrow(errors)),]
library(plyr)
install.packages("plyr")
install.packages("dplyr")
install.packages("randomForest")
errors <- errors[sample(1:nrow(errors)),]
library(plyr)
library(dplyr)
errors <- ddply(.data = errors, .variables = c("id"), .fun = norm_errors)
errors <- as.data.frame(errors)
errors$reference_flag <- as.factor(errors$reference_flag)
load("\Users\Brett\Downloads\errors_consensus_r0.RData")
load("\Users\Brett\Downloads\errors_consensus_r0.RData")
load("\\Users\\Brett\Downloads\\errors_consensus_r0.RData")
load("\\Users\\Brett\\Downloads\\errors_consensus_r0.RData")
errors <- errors[sample(1:nrow(errors)),]
library(plyr)
library(dplyr)
errors <- ddply(.data = errors, .variables = c("id"), .fun = norm_errors)
errors <- as.data.frame(errors)
errors$reference_flag <- as.factor(errors$reference_flag)
train_rnas = "1KKA 1L1W 1LC6 1LDZ 1NC0 1OW9 1PJY 1R7W 1SCL 1UUU 1XHP 1YSV 1Z2J 1ZC5 2FDT 2JWV 2K66 2KOC 2L3E 2LBJ 2LBL 2LDL 2LDT 2LHP 2LI4 2LK3 2LP9 2LPA 2LQZ 2LU0 2LUB"
test_rnas = "2LUN 2LV0 2M12 2M21 2M22 2M24 2M4W 2M5U 2M8K 2MEQ 2MFD 2MHI 2MNC 2MXL 2N2O 2N2P 2N4L 2N6S 2N6T 2N6W 2N6X"
train_rnas <- unlist(strsplit(train_rnas, " "))
test_rnas <- unlist(strsplit(test_rnas, " "))
train <- errors[(errors$id %in% train_rnas), !(colnames(errors) %in% c("id", "model"))]
test <- errors[(errors$id %in% test_rnas), !(colnames(errors) %in% c("id", "model"))]
test_info <- errors[(errors$id %in% test_rnas), (colnames(errors) %in% c("id", "model"))]
train[is.na(train)] <- 9999
test[is.na(test)] <- 9999
names <- unlist(strsplit("reference_flag C1p C2p C3p C4p C5p C2 C5 C6 C8 H1p H2p H3p H4p H5p H5pp H2 H5 H6 H8 total", " "))
colnames(train) <- names
colnames(test) <- names
n_true <- sum(train$reference_flag==1)
n_false <- sum(train$reference_flag==0)
n_minor <- abs(n_true-n_false)
train_true <- subset(train, reference_flag==1)
train_false <- subset(train, reference_flag==0)
train_balance <-  rbind(train_true, rbind(train_false, train_false[sample(1:nrow(train_false), n_minor, replace = TRUE), ]))
library(randomForest)
library(caret)
install.packages("caret")
install.packages("caretEnsemble")
library(randomForest)
library(caret)
install.packages("ggplot2")
library(randomForest)
library(caret)
rf <- randomForest(formula = reference_flag~., data = train_balance, na.action = na.exclude, do.trace = TRUE, ntree = 500, cutoff = c(0.6,0.4))
test$reference_flag_binary <- predict(rf, test, type = "response")
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
test <- cbind(test_info, test)
test <- test[order(test[,c("total")], decreasing = FALSE), ]
test_nslr_total_error <- ddply(.data = test, .variables = c("id"), .fun = scores, N=1)
test <- test[order(test[,c("reference_flag_prob")][,1]), ]
library(plyr)
library(dplyr)
test$reference_flag_binary <- predict(rf, test, type = "response")
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
t <- confusionMatrix(test$reference_flag, predict(rf, test))
library(randomForest)
library(caret)
rf <- randomForest(formula = reference_flag~., data = train_balance, na.action = na.exclude, do.trace = TRUE, ntree = 500, cutoff = c(0.6,0.4))
test$reference_flag_binary <- predict(rf, test, type = "response")
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
library(caret)
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
t <- caret::confusionMatrix(test$reference_flag, predict(rf, test))
install.packages("pbkrtest")
test$reference_flag_prob <- predict(rf, test, type = "prob")
t <- caret::confusionMatrix(test$reference_flag, predict(rf, test))
clearPushBack()
cat("\014")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
install.packages("heuristica")
library(heuristica)
t <- confusionMatrix(test$reference_flag, predict(rf, test))
cat("\014")
t <- confusionMatrix(test$reference_flag, predict(rf, test))
install.packages('knitr')
install.packages('rmarkdown')
install.packages(c("assertthat", "backports", "BH", "car", "caret", "checkmate", "DBI", "digest", "dplyr", "foreach", "foreign", "formatR", "Formula", "glue", "gridExtra", "highr", "Hmisc", "htmlTable", "htmltools", "htmlwidgets", "httpuv", "iterators", "jsonlite", "lazyeval", "markdown", "MASS", "mgcv", "mime", "nnet", "pbapply", "quantreg", "R6", "randomForest", "Rcpp", "reshape2", "scales", "shiny", "SparseM", "stringi", "survival", "tibble", "viridis", "xtable", "yaml"))
devtools::install_url("http://cran.r-project.org/src/contrib/rmarkdown0.5.1.tar.gz")
getwd()
setwd("C:/Users/Brett/Documents/Umich/415final")
knitr::opts_chunk$set(echo = TRUE)
test_flights = read.csv("test_flights.csv")
test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights") ;
test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
library(ISLR)
Hitters=na.omit(Hitters)
install.packages("ISLR")
install.packages("MASS")
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
with(Hitters,sum(is.na(Salary)))
library(leaps)
install.packages("leaps")
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
flights = read.csv("flights_reducedcsv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
flights = read.csv("flights_reduced.cs"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
flights = read.csv("flights_reduced.csv);test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
knitr::opts_chunk$set(echo = TRUE)
flights = read.csv("flights_reduced.csv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
View(flights)
flights = read.csv("flights_reduced.csv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
require(ISLR)
require(tree)
attach(Carseats)
hist(Sales)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats, High)
tree.carseats=tree(High~.-Sales,data=Carseats)
install.packages("tree")
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
with(Hitters,sum(is.na(Salary)))
library(leaps)
regfit.full=regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
plot(regfit.fwd,scale="Cp")
dim(Hitters)
set.seed(1)
train=sample(seq(263),180,replace=FALSE)
train
regfit.fwd=regsubsets(Salary~.,data=Hitters[train,],nvmax=19,method="forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~.,data=Hitters[-train,])# notice the -index!
for(i in 1:19){
coefi=coef(regfit.fwd,id=i)
pred=x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors),ylab="Root MSE",ylim=c(300,400),pch=19,type="b")
points(sqrt(regfit.fwd$rss[-1]/180),col="blue",pch=19,type="b")
legend("topright",legend=c("Training","Validation"),col=c("blue","black"),pch=19)
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds=sample(rep(1:10,length=nrow(Hitters)))
folds
table(folds)
cv.errors=matrix(NA,10,19)
for(k in 1:10){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=k,],nvmax=19,method="forward")
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==k,],id=i)
cv.errors[k,i]=mean( (Hitters$Salary[folds==k]-pred)^2)
}
}
rmse.cv=sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
library(glmnet)
summary(flights)
#summary(flights)
library(leaps)
regfit.full=regsubsets(CANCELLED~.,data=flights)
summary(flights)
library(leaps)
summary(flights)
flights. <- factor(schtyp, labels = c("private", "public"))
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
summary(flights)
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
flights["WEATHER_DELAY"] = factor(flights["WEATHER_DELAY"], levels = c("Yes", "No"))
summary(flights)
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
flights["WEATHER_DELAY"] = factor(flights["WEATHER_DELAY")
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
flights["WEATHER_DELAY"] = factor(flights["WEATHER_DELAY"])
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
flights["WEATHER_DELAY"] = as.factor(flights["WEATHER_DELAY"])
summary(flights)
flights["WEATHER_DELAY"] = apply(flights["WEATHER_DELAY"], 2, function(x)ifelse(x>0, 1, 0))
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
summary(flights)
summary(flights)
flights$WEATHER_DELAY = apply(flights$WEATHER_DELAY, 2, function(x)ifelse(x>0, 1, 0))
flights = read.csv("flights_reduced.csv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
summary(flights)
flights$WEATHER_DELAY = apply(flights$WEATHER_DELAY, 2, function(x)ifelse(x>0, 1, 0))
summary(flights)
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
summary(flights)
flights = read.csv("flights_reduced.csv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
summary(flights)
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
flights$LATE_AIRCRAFT_DELAY= ifelse(flights$LATE_AIRCRAFT_DELAY > 0, 1, 0)
flights$LATE_AIRCRAFT_DELAY = as.factor(flights$LATE_AIRCRAFT_DELAY)
flights$AIRLINE_DELAY= ifelse(flights$AIRLINE_DELAY > 0, 1, 0)
flights$AIRLINE_DELAY = as.factor(flights$AIRLINE_DELAY)
flights$SECURITY_DELAY= ifelse(flights$SECURITY_DELAY > 0, 1, 0)
flights$SECURITY_DELAY = as.factor(flights$SECURITY_DELAY)
flights$AIR_SYSTEM_DELAY= ifelse(flights$AIR_SYSTEM_DELAY > 0, 1, 0)
flights$AIR_SYSTEM_DELAY = as.factor(flights$AIR_SYSTEM_DELAY)
summary(flights)
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
flights$LATE_AIRCRAFT_DELAY= ifelse(flights$LATE_AIRCRAFT_DELAY > 0, 1, 0)
flights$LATE_AIRCRAFT_DELAY = as.factor(flights$LATE_AIRCRAFT_DELAY)
flights$AIRLINE_DELAY= ifelse(flights$AIRLINE_DELAY > 0, 1, 0)
flights$AIRLINE_DELAY = as.factor(flights$AIRLINE_DELAY)
flights$SECURITY_DELAY= ifelse(flights$SECURITY_DELAY > 0, 1, 0)
flights$SECURITY_DELAY = as.factor(flights$SECURITY_DELAY)
flights$AIR_SYSTEM_DELAY= ifelse(flights$AIR_SYSTEM_DELAY > 0, 1, 0)
flights$AIR_SYSTEM_DELAY = as.factor(flights$AIR_SYSTEM_DELAY)
flights$CANCELLED = as.factor(flights$CANCELLED)
summary(flights)
flights = read.csv("flights_reduced.csv"); test_flights = read.csv("test_flights.csv"); train_flights = read.csv("train_flights.csv") ;
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
flights$LATE_AIRCRAFT_DELAY= ifelse(flights$LATE_AIRCRAFT_DELAY > 0, 1, 0)
flights$LATE_AIRCRAFT_DELAY = as.factor(flights$LATE_AIRCRAFT_DELAY)
flights$AIRLINE_DELAY= ifelse(flights$AIRLINE_DELAY > 0, 1, 0)
flights$AIRLINE_DELAY = as.factor(flights$AIRLINE_DELAY)
flights$SECURITY_DELAY= ifelse(flights$SECURITY_DELAY > 0, 1, 0)
flights$SECURITY_DELAY = as.factor(flights$SECURITY_DELAY)
flights$AIR_SYSTEM_DELAY= ifelse(flights$AIR_SYSTEM_DELAY > 0, 1, 0)
flights$AIR_SYSTEM_DELAY = as.factor(flights$AIR_SYSTEM_DELAY)
flights$CANCELLED = as.factor(flights$CANCELLED)
summary(flights)
View(flights)
View(flights)
View(best.fit)
flights = read.csv("flights_reduced.csv");
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
flights$LATE_AIRCRAFT_DELAY= ifelse(flights$LATE_AIRCRAFT_DELAY > 0, 1, 0)
flights$LATE_AIRCRAFT_DELAY = as.factor(flights$LATE_AIRCRAFT_DELAY)
flights$AIRLINE_DELAY= ifelse(flights$AIRLINE_DELAY > 0, 1, 0)
flights$AIRLINE_DELAY = as.factor(flights$AIRLINE_DELAY)
flights$SECURITY_DELAY= ifelse(flights$SECURITY_DELAY > 0, 1, 0)
flights$SECURITY_DELAY = as.factor(flights$SECURITY_DELAY)
flights$AIR_SYSTEM_DELAY= ifelse(flights$AIR_SYSTEM_DELAY > 0, 1, 0)
flights$AIR_SYSTEM_DELAY = as.factor(flights$AIR_SYSTEM_DELAY)
flights$CANCELLED = as.factor(flights$CANCELLED)
summary(flights)
flights = read.csv("flights_reduced.csv");
rm(flights$X)
View(flights)
View(flights)
flights = read.csv("flights_reduced.csv");
flights = flights[-X]
flights = read.csv("flights_reduced.csv");
flights = flights[-'X']
flights = read.csv("flights_reduced.csv");
flights$X = NULL
flights$WEATHER_DELAY= ifelse(flights$WEATHER_DELAY > 0, 1, 0)
flights$WEATHER_DELAY = as.factor(flights$WEATHER_DELAY)
flights$LATE_AIRCRAFT_DELAY= ifelse(flights$LATE_AIRCRAFT_DELAY > 0, 1, 0)
flights$LATE_AIRCRAFT_DELAY = as.factor(flights$LATE_AIRCRAFT_DELAY)
flights$AIRLINE_DELAY= ifelse(flights$AIRLINE_DELAY > 0, 1, 0)
flights$AIRLINE_DELAY = as.factor(flights$AIRLINE_DELAY)
flights$SECURITY_DELAY= ifelse(flights$SECURITY_DELAY > 0, 1, 0)
flights$SECURITY_DELAY = as.factor(flights$SECURITY_DELAY)
flights$AIR_SYSTEM_DELAY= ifelse(flights$AIR_SYSTEM_DELAY > 0, 1, 0)
flights$AIR_SYSTEM_DELAY = as.factor(flights$AIR_SYSTEM_DELAY)
flights$CANCELLED = as.factor(flights$CANCELLED)
summary(flights)
library(leaps)
regfit.full=regsubsets(CANCELLED~.,data=flights)
